# ğŸš€ Building a RAG-Powered Web Content Question-Answering System with Citation Support

---

## ğŸ¯ Problem Statement
Website Retrieval Assignment - Developed a Retrieval Augmented Generation (RAG) system to answer questions based on content from specific websites.
- ğŸ” Retrieves relevant, up-to-date content from specific websites  
- ğŸ§  Combines that with **LLM (Large Language Model) generation**  
- ğŸ“‘ Provides **citations (links back to the source)** for transparency  
- ğŸ” Allows **user authentication** before use  

---
### ğŸ“‚ Project Structure
```bash
RAG-QA-APP/
â”‚
â”œâ”€â”€ backend/                     # Backend service (FastAPI)
â”‚   â”œâ”€â”€ __init__.py              # Marks package, can include initialization code
â”‚   â”œâ”€â”€ auth.py                  # Handles authentication (JWT, user auth, etc.)
â”‚   â”œâ”€â”€ embeddings.py            # Embedding generation logic
â”‚   â”œâ”€â”€ engine.py                # Core RAG engine (retrieval + generation)
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point
â”‚   â”œâ”€â”€ models.py                # Pydantic models / schema definitions
â”‚   â”œâ”€â”€ router.py                # API routes definition
â”‚   â”œâ”€â”€ vector_store.py          # Vector database operations (Chroma)
â”‚   â””â”€â”€ web_loader.py            # Logic to fetch and preprocess website content
â”‚
â”œâ”€â”€ frontend/                    # Frontend service (Streamlit)
â”‚   â”œâ”€â”€ app.py                   # Frontend app entry point
â”‚
â”œâ”€â”€ .env                         # Environment variables (API keys, configs)
â”œâ”€â”€ requirements.txt             # Python dependencies

```
---
## ğŸ§© Architecture Overview

### ğŸ”¹ 1. Data Source & Indexing
- Users supply website URLs via the **Streamlit frontend**.  
- **`web_loader.py`** â†’ Fetches HTML content (BeautifulSoup + Readability).  
- **`engine.py`**:
  - Splits content into chunks (LangChain `RecursiveCharacterTextSplitter`).  
  - Generates embeddings using either:
    - **OpenAI embeddings** (if `OPENAI_API_KEY` set), or  
    - **SentenceTransformers / HuggingFace models** (offline).  
  - Stores chunks + embeddings in **ChromaDB** (persistent vector DB).  

ğŸ‘‰ Supports **Replace** mode (wipe & re-index).

---

### ğŸ”¹ 2. Vector Database
- **`vector_store.py`** manages **Chroma collections**:
  - Stores text chunks, embeddings, and metadata (`url`, `title`, `chunk_id`, etc.).  
  - Supports **reset, add, query, and metadata fetch**.  
- Retrieval uses **cosine similarity** to find the most relevant chunks.  

---

### ğŸ”¹ 3. Retrieval-Augmented Generation (RAG)
- **`engine.py â†’ retrieve()`**:
  - Encodes user query into embeddings.  
  - Finds top-K relevant document chunks.  
- **`router.py`**:
  - Handles `/api/v1/chat`.  
  - Calls engineâ€™s retrieval.  
  - Uses **LangChainâ€™s RetrievalQA + LLM** for polished answers.  
  - Attaches **citations**: snippet text, URL, and title.  

---

### ğŸ”¹ 4. API Layer (Backend - FastAPI)
- **`main.py`** â†’ initializes FastAPI app.  
- **`router.py`** â†’ defines endpoints:  
  - `POST /api/v1/login` â†’ JWT authentication  
  - `POST /api/v1/index` â†’ Index new URLs  
  - `GET  /api/v1/index` â†’ List indexed URLs  
  - `POST /api/v1/chat` â†’ Ask a question, get RAG-powered answer with citations  
- **`auth.py`** â†’ Implements JWT-based authentication (with expiration).  

---

### ğŸ”¹ 5. Frontend (Streamlit)
- **`app.py`** provides a **multi-step interface**:
  1. Login (JWT-protected)   
  3. Indexing Page (enter URLs â†’ index into Chroma)  
  4. Chat Page (ask questions â†’ get answers + citations)  

- Answers appear in **highlighted cards**.  
- Citations show **exact sources inline** after the content.  

---

### ğŸ”¹ 6. Authentication
- User must **login first** with credentials from `.env`.  
- JWT tokens are issued by **FastAPI backend** and stored in session.  
- All API requests from Streamlit include the token in headers.  

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technology                               |
|--------------|------------------------------------------|
| Frontend     | Streamlit                                |
| Backend      | FastAPI                                  |
| Embeddings   | OpenAI API / SentenceTransformers        |
| Vector DB    | ChromaDB                                 |
| Orchestration| LangChain                                |
| Auth         | JWT (`python-jose`, `PyJWT`)             |
| Scraping     | Requests + BeautifulSoup + Readability   |
| Deployment   | Local / Cloud (AWS, GCP, Heroku)         |

---

## ğŸ” Business Use Cases
- Question-answering systems for company documentation/knowledge bases
- Automated customer support using website content
- Information retrieval from multiple web sources
- Content-aware chatbots with citation capabilities

---

## ğŸ“Š Workflow Example

1. User logs in with **username/password**.  
2. Enters URLs â†’ system fetches and indexes content.  
3. User asks: *â€œWhat is Retrieval-Augmented Generation?â€*  
4. Backend:  
   - Embeds query â†’ finds matching chunks from indexed sites.  
   - LLM generates coherent summary.  
   - Citations are attached.  
5. Streamlit UI shows answer:  

> **Answer**  
> Retrieval-Augmented Generation (RAG) combines retrieval from external data with generation using large language models, ensuring accurate and grounded responses.  
>  
> **From [huyenchip.com](https://huyenchip.com/2024/07/25/genai-platform.html):**  
> â€œThis is what the overall architecture looks likeâ€¦â€  

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone & Install
```bash
git clone https://github.com/SSaranya19/RAG-Website-Retrieval-QA.git
cd RAG-Website-Retrieval-QA
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt
Copy .env.example â†’ .env and set values.
Run Backend : uvicorn backend.main:app --reload --port 8000
Run Frontend: streamlit run app.py
